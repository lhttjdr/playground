{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5WvP0OR7iJQ"
   },
   "source": [
    "# LCEL\n",
    "\n",
    "LangChain 表达式语言（LangChain Expression Language，LCEL）是一种声明式的方法，可以轻松地将\"链\"组合在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o8tje-YSYYO"
   },
   "source": [
    "## 1.基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8MArB06nlQa"
   },
   "source": [
    "### 1.1 函数\n",
    "\n",
    "(程序语言中的)函数一般看作是对象(object)间的态射(morphsim)，即输入到输出的变换。例如：\n",
    "\n",
    "$$f: y\\to z\\qquad h: x\\to y$$\n",
    "\n",
    "※ 简单起见，多个输入参数，可以视为一个元组(tuple)类型的输入参数。\n",
    "\n",
    "将函数也看作一个对象（object），那么函数和函数也是可以进行运算的。复合函数\n",
    "\n",
    "$$h(x)=(f\\cdot g)(x)=f(g(x))$$\n",
    "\n",
    "$$h = f\\cdot g$$\n",
    "\n",
    "其中的 \"$\\cdot$\" 就是函数的结合（composition）运算。\n",
    "\n",
    "\n",
    "Langchain就是把各种函数都封装成`Runnable[Input, Output]`，然后使用运算符`|`进行结合运算。\n",
    "\n",
    "※ `Runnable[Input, Output]`是Python的泛型写法。它和Java的`Function<T, R>`是一个意思。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "243qogaxoSvt"
   },
   "source": [
    "### 1.2 运算符重载\n",
    "\n",
    "LCEL的管道(pipe)`|`运算是基于Python中运算符重载实现的。\n",
    "\n",
    "- `__or__`：左结合`|`运算\n",
    "- `__ror__`：右结合`|`运算\n",
    "\n",
    "※ 对于数字来说，它们通常表示位运算。但对于一般的其它类型，位运算没有意义，所以它可以拿来用做其他用途了。就比如LangChain，把它们用于函数的复合运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrVOGjULoYLH",
    "outputId": "76574ea2-c940-4710-8b53-2d789b310825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A's __or__ method is called\n",
      "A's __or__ method is called\n",
      "B's __or__ method is called\n",
      "B's __or__ method is called\n",
      "D's __ror__ method is called\n",
      "D's __ror__ method is called\n",
      "A's __or__ method is called\n",
      "A's __or__ method is called\n"
     ]
    }
   ],
   "source": [
    "# __or__运算\n",
    "class A:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __or__(self, other):\n",
    "        print(\"A's __or__ method is called\")\n",
    "        return self.value | other.value\n",
    "\n",
    "\n",
    "class B:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __or__(self, other):\n",
    "        print(\"B's __or__ method is called\")\n",
    "        return self.value | other.value\n",
    "\n",
    "\n",
    "objA = A(2)\n",
    "objB = B(3)\n",
    "result = objA | objB  # 这个 | 是左结合的，等价于调用左操作数(objA)的__or__方法\n",
    "result = objA.__or__(objB)\n",
    "\n",
    "result = objB | objA  # 这个 | 是左结合的，等价于调用左操作数(objB)的__or__方法\n",
    "result = objB.__or__(objA)\n",
    "\n",
    "\n",
    "# __ror__运算\n",
    "class C:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "class D:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __ror__(self, other):\n",
    "        print(\"D's __ror__ method is called\")\n",
    "        return self.value | other.value\n",
    "\n",
    "\n",
    "objC = C(4)\n",
    "objD = D(5)\n",
    "result = objC | objD  # 这个 | 是右结合的，等价于调用右操作数(objD)的__ror__方法\n",
    "result = objD.__ror__(objC)\n",
    "\n",
    "\n",
    "# 如下，调用objA的__or__方法？还是调用objD的__ror__方法？\n",
    "result = objA | objD  # 左结合的优先级高，因此调用objA的__or__方法\n",
    "result = objA.__or__(objD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oWXlYIevtHT"
   },
   "source": [
    "那么，函数的复合运算就容易实现了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8eQmBoFv1Id",
    "outputId": "d2881f42-1e78-4bee-bc39-2d97b61e760e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "35\n",
      "77\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "from typing_extensions import Self\n",
    "\n",
    "\n",
    "# \"函数\"的抽象类，用于描述任意函数\n",
    "class Func(ABC):\n",
    "    # 函数原型 （为简化问题，不考虑参数类型，所以不需要泛型）\n",
    "    @abstractmethod\n",
    "    def call(self, x: Any) -> Any:\n",
    "        pass\n",
    "\n",
    "    # 复合运算\n",
    "    def __or__(self, other: Self) -> Self:\n",
    "        return FuncSeq([self, other])\n",
    "\n",
    "    def __ror__(self, other: Self) -> Self:\n",
    "        return FuncSeq([other, self])\n",
    "\n",
    "\n",
    "# 复合函数， 例如 f*g\n",
    "class FuncSeq(Func):\n",
    "    # 需要结合运算的函数们，例如，f，g\n",
    "    functions: list[Func] = []\n",
    "\n",
    "    def __init__(self, functions: list[Func]):\n",
    "        self.functions = functions\n",
    "\n",
    "    # 复合函数运算规则：复合函数，等价于逐层调用各个函数\n",
    "    def call(self, x: Any) -> Any:\n",
    "        result = x\n",
    "        for f in self.functions:\n",
    "            result = f.call(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Add(Func):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.value + x\n",
    "\n",
    "\n",
    "class Mult(Func):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.value * x\n",
    "\n",
    "\n",
    "add = Add(6)\n",
    "print(add.call(5))  # 5 + 6 = 11\n",
    "\n",
    "mult = Mult(7)\n",
    "print(mult.call(5))  # 5 * 7 = 35\n",
    "\n",
    "chain = add | mult\n",
    "print(chain.call(5))  # (5 + 6) * 7 = 77\n",
    "\n",
    "chain = mult | add\n",
    "print(chain.call(5))  # 5 * 7 + 6 = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JFkNxyfS3Kk"
   },
   "source": [
    "## 2.基本的类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLxroR6d8vBw"
   },
   "source": [
    "### 2.1 Runnable基类\n",
    "\n",
    "抽象类\n",
    "\n",
    "```\n",
    "Runnable[Input, Output]\n",
    "```\n",
    "\n",
    "任意可执行部件的基类。通过重载`__or__`和`__ror__`运算符，实现了管道运算。\n",
    "\n",
    "子类需要实现下面一些接口，增加实际也业务逻辑。\n",
    "\n",
    "- **invoke/ainvoke**: 将一个输入变换成输入\n",
    "- **batch/abatch**: 批量地将多个输入变换成输出\n",
    "- **stream/astream**: 将一个输入变换成输入，以流的形式返回\n",
    "- **astream_log**: 将一个输入变换成输出，将输出结果和指定的中间结果以流的形式返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OeHkBC4_RxJ",
    "outputId": "373811c8-8847-4850-cf08-c6530ef60b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "3\n",
      "{'counter': 2}\n",
      "{'counter': 6}\n",
      "{'counter': 9}\n",
      "{'counter': 8}\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from operator import itemgetter\n",
    "from typing import Any\n",
    "\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from typing_extensions import override\n",
    "\n",
    "\n",
    "# 例如，一个自定义的Runnable子类，实现了\"加一\"功能\n",
    "class CustomRunnable(Runnable[int, int]):\n",
    "\n",
    "    @override\n",
    "    def invoke(self, x: int, config: RunnableConfig | None = None, **kwargs) -> int:\n",
    "        return x + 1\n",
    "\n",
    "\n",
    "runnable = CustomRunnable()\n",
    "print(runnable.invoke(1))  # 1+1应该输出2\n",
    "\n",
    "runnable1 = CustomRunnable()\n",
    "runnable2 = CustomRunnable()\n",
    "\n",
    "runnable3 = runnable1 | runnable2  # 管道运算， runnable1\"加1\"结果传给runnable2,再\"加1\"\n",
    "print(runnable3.invoke(1))  # 1+1+1应该输出3\n",
    "\n",
    "# 等价于下面的调用\n",
    "print(runnable2.invoke(runnable1.invoke(1)))  # 应该输出3\n",
    "\n",
    "\n",
    "# 特别地，callable 会自动转换成Runnable的\n",
    "# 例如，一个自定义的Runnable子类，实现了\"加一\"功能\n",
    "class AnotherRunnable(Runnable[dict, dict]):\n",
    "\n",
    "    @override\n",
    "    def invoke(self, x: dict, config: RunnableConfig | None = None, **kwargs) -> dict:\n",
    "        return {\"counter\": x[\"counter\"] + 1}\n",
    "\n",
    "\n",
    "runnable = AnotherRunnable()\n",
    "print(runnable.invoke({\"counter\": 1}))  # 1+1应该输出2\n",
    "\n",
    "\n",
    "# 函数counter是callable类型的\n",
    "def counter(x: int) -> dict:\n",
    "    return {\"counter\": x}\n",
    "\n",
    "\n",
    "runnable1 = counter | runnable\n",
    "print(runnable1.invoke(5))  # 5+1应该输出6\n",
    "\n",
    "# dict中的字段也会处理\n",
    "runnable1 = {\"counter\": lambda x: x + 1} | runnable\n",
    "print(runnable1.invoke(7))  # 7+1+1应该输出9\n",
    "\n",
    "runnable2 = {\"counter\": CustomRunnable()} | runnable\n",
    "print(runnable2.invoke(6))  # 6+1+1应该输出8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e61YZB2-8xPO"
   },
   "source": [
    "#### 2.1.1 RunnableSerializable 子类\n",
    "\n",
    "抽象类\n",
    "\n",
    "```\n",
    "Runnable -> RunnableSerializable\n",
    "```\n",
    "\n",
    "增加了序列化相关的功能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThTasFNt77m7",
    "outputId": "c8dbf396-eee0-40d2-f648-bdf4375c3f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "{'lc': 1, 'type': 'not_implemented', 'id': ['__main__', 'SquareCalculator'], 'repr': 'SquareCalculator(number=5.0)', 'name': 'SquareCalculator', 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'SquareCalculatorInput'}, {'id': 1, 'type': 'runnable', 'data': {'id': ['__main__', 'SquareCalculator'], 'name': 'SquareCalculator'}}, {'id': 2, 'type': 'schema', 'data': 'SquareCalculatorOutput'}], 'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}\n",
      "True\n",
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnablePassthrough'], 'kwargs': {}, 'name': 'RunnablePassthrough', 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PassthroughInput'}, {'id': 1, 'type': 'runnable', 'data': {'id': ['langchain', 'schema', 'runnable', 'RunnablePassthrough'], 'name': 'RunnablePassthrough'}}, {'id': 2, 'type': 'schema', 'data': 'PassthroughOutput'}], 'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableSerializable\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "\n",
    "class SquareCalculator(RunnableSerializable):\n",
    "    number: float = 0.0\n",
    "\n",
    "    def invoke(self, config: RunnableConfig | None = None, **kwargs) -> float:\n",
    "        # Calculate the square of the input number\n",
    "        return self.number**2\n",
    "\n",
    "\n",
    "square = SquareCalculator(number=5)\n",
    "print(square.invoke({}))\n",
    "print(square.to_json())\n",
    "\n",
    "# 例如，后面要讲的RunnablePassthrough就是一个RunnableSerializable的子类\n",
    "runnable = RunnablePassthrough()\n",
    "print(isinstance(runnable, RunnableSerializable))\n",
    "print(runnable.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTVIEpwwQVRB"
   },
   "source": [
    "### 2.2 两种基础的Runnable\n",
    "\n",
    "两种基本的Runnable对应了函数和生成器。\n",
    "\n",
    "- `RunnableLambda`：函数\n",
    "- `RunnableGenerator`：生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KxCIii0_wMA"
   },
   "source": [
    "#### 2.2.1 RunnableLambda\n",
    "\n",
    "```\n",
    "Runnable -> RunnableLambda\n",
    "```\n",
    "\n",
    "它包装一个Python的`Callable`对象。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "puAJFTVmAAu8",
    "outputId": "3d3ae0e3-8055-4b2e-9d57-8be2ab216384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! Alice'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable = RunnableLambda(lambda name: f\"Hello! {name}\")\n",
    "\n",
    "runnable.invoke(\"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fAowtQbA-kX",
    "outputId": "dcdaa6eb-08f0-422f-fc7b-4fe09197c3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Bob\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "class Dummy:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def hello_x(self):\n",
    "        return f\"Hello {self.x}\"\n",
    "\n",
    "\n",
    "runnable = RunnableLambda(Dummy.hello_x)\n",
    "dummy = Dummy(\"Bob\")\n",
    "\n",
    "print(runnable.invoke(dummy))\n",
    "print(isinstance(runnable, Runnable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsbCkdIfGEJY"
   },
   "source": [
    "#### 2.2.2 RunnableGenerator\n",
    "\n",
    "```\n",
    "Runnable -> RunnableGenerator\n",
    "```\n",
    "\n",
    "包装的生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8k6h6fzuGR4P",
    "outputId": "26a9acbd-b281-4410-a945-e2d49fd9ce0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello' id='run-23847f65-0c22-4ddf-92a7-90c94d20bd71-0'\n",
      "content='How are you?' id='run-8343b5a0-1e65-4daa-9804-c9a8933e8b40-0'\n",
      "[AIMessageChunk(content='H', id='run-ec129d5a-0c61-43b7-a9b3-3e28b0fdad1c'), AIMessageChunk(content='e', id='run-ec129d5a-0c61-43b7-a9b3-3e28b0fdad1c'), AIMessageChunk(content='l', id='run-ec129d5a-0c61-43b7-a9b3-3e28b0fdad1c'), AIMessageChunk(content='l', id='run-ec129d5a-0c61-43b7-a9b3-3e28b0fdad1c'), AIMessageChunk(content='o', id='run-ec129d5a-0c61-43b7-a9b3-3e28b0fdad1c')]\n",
      "Received:  content='H' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='o' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='w' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content=' ' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='a' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='r' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='e' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content=' ' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='y' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='o' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='u' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "Received:  content='?' id='run-76013003-915f-426e-896d-2eb205b02caf'\n",
      "[(1, AIMessageChunk(content='H', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='o', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='w', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content=' ', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='a', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='r', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='e', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content=' ', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='y', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='o', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='u', id='run-76013003-915f-426e-896d-2eb205b02caf')), (1, AIMessageChunk(content='?', id='run-76013003-915f-426e-896d-2eb205b02caf'))]\n",
      "Received:  content='Hello' id='run-c9b13746-d87d-4d8b-8214-0b34b59a0a78-0'\n",
      "(5, AIMessage(content='Hello', id='run-c9b13746-d87d-4d8b-8214-0b34b59a0a78-0'))\n",
      "Received:  content='How are you?' id='run-19d8403c-97e5-423a-86cd-462239d024da-0'\n",
      "(12, AIMessage(content='How are you?', id='run-19d8403c-97e5-423a-86cd-462239d024da-0'))\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.fake import FakeListChatModel\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "\n",
    "chat = FakeListChatModel(responses=[\"Hello\", \"How are you?\"])\n",
    "\n",
    "print(chat.invoke(\"hello\"))\n",
    "print(chat.invoke(\"hello\"))\n",
    "print(list(chat.stream(\"hello\")))\n",
    "\n",
    "\n",
    "def add_chunk_langth_generator(iterator):\n",
    "    \"\"\"generator of a tuple of chank length and chank.\"\"\"\n",
    "    for ai_message in iterator:\n",
    "        print(\"Received: \", ai_message)  # for debug\n",
    "        yield (len(ai_message.content), ai_message)\n",
    "\n",
    "\n",
    "runnable_generator = RunnableGenerator(add_chunk_langth_generator)\n",
    "chat1 = chat | runnable_generator\n",
    "print(list(chat1.stream(\"hello\")))\n",
    "\n",
    "# 调用invoke的话，那么整条链每个Runnable都调用invoke。\n",
    "# 所以chat调用invoke，返回的AIMessage而不是AIMessageChunk了\n",
    "print(chat1.invoke(\"hello\"))\n",
    "print(chat1.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFJDZfusK_ca"
   },
   "source": [
    "## 3.RunnableSerializable的子类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlijJz2WPOnI"
   },
   "source": [
    "### 3.1 Runnable组合运算\n",
    "\n",
    "Runnable的结合方法有两种：\n",
    "\n",
    "*   串联：`RunnableSequence`\n",
    "*   并联: `RunnableParallel`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6keEiqJucRQ"
   },
   "source": [
    "#### 3.1.1 RunnableSequence\n",
    "\n",
    "```\n",
    "Runnable -> RunnableSequence\n",
    "```\n",
    "\n",
    "管道运算的结果，都是`RunnableSequence`类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhcxi6Wruqev",
    "outputId": "84d16cee-59e7-4bd5-872d-a1a51d541547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "True\n",
      "False\n",
      "[(-1, 1), 10]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "r1 = RunnableLambda(lambda x: x)\n",
    "r2 = RunnableLambda(lambda x: (x, 1))\n",
    "r3 = RunnableLambda(lambda x: [x, 10])\n",
    "\n",
    "seq = r1 | r2 | r3\n",
    "\n",
    "print(type(seq))\n",
    "print(isinstance(seq, RunnableSequence))\n",
    "print(isinstance(r1, RunnableSequence))\n",
    "\n",
    "print(seq.invoke(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCKj_7z6wf4-"
   },
   "source": [
    "#### 3.1.2 RunnableParallel\n",
    "\n",
    "并行执行多条链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrMAZS6oxJgm",
    "outputId": "13ef268d-7ba6-4ccd-d8d0-9292df0427ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello, I am Alice.' id='run-6ca22a55-7c3c-4caf-b0ee-629246f3363f-0'\n",
      "content='Hello, I am Bob.' id='run-8d354469-3903-4151-9ee5-05c38b3e7f0b-0'\n",
      "{'alice': AIMessage(content='Hello, I am Alice.', id='run-a769a166-09dc-4014-aef6-9a12f065104e-0'), 'bob': AIMessage(content='Hello, I am Bob.', id='run-f1affb7e-7c70-4612-8c72-717166d523ef-0')}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.fake import FakeListChatModel\n",
    "from langchain_core.runnables import RunnableGenerator, RunnableParallel\n",
    "\n",
    "chat1 = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"Hello, I am Alice.\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat2 = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"Hello, I am Bob.\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat1.invoke(\"hello\"))\n",
    "print(chat2.invoke(\"hello\"))\n",
    "\n",
    "# 并行地执行\n",
    "runnable = RunnableParallel(alice=chat1, bob=chat2)\n",
    "print(runnable.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgEgZQ3UyIwc"
   },
   "source": [
    "##### RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLigSGAnyM9N",
    "outputId": "265aa9bd-fb47-4d93-b41d-5ff04f75005d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alice': AIMessage(content='Hello, I am Alice.', id='run-427c8e71-0166-4971-9e1b-52e5db037e20-0'), 'bob': AIMessage(content='Hello, I am Bob.', id='run-047b2b1f-d90c-4f52-b262-59db82fbcc11-0')}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "runnable = RunnableMap(alice=chat1, bob=chat2)\n",
    "print(runnable.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6oVETLTLQO5"
   },
   "source": [
    "### 3.2 流程控制\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPXxJGoUQacD"
   },
   "source": [
    "#### 3.2.1 RunnableBranch\n",
    "\n",
    "多条件分支\n",
    "\n",
    "\n",
    "\n",
    "1.   必须有2个以上分支\n",
    "2.   必须有default分支。default分支位于最后\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRBsA0hlQhZ6",
    "outputId": "a155861d-ce31-453f-b643-881ae00af84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is positive!\n",
      "-1 is negative!\n",
      "0 is Zero!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: x > 0, lambda x: f\"{x} is positive!\"),\n",
    "    (lambda x: x < 0, lambda x: f\"{x} is negative!\"),\n",
    "    lambda x: f\"{x} is Zero!\",\n",
    ")\n",
    "\n",
    "print(branch.invoke(1))\n",
    "print(branch.invoke(-1))\n",
    "print(branch.invoke(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2rNzDNAHRaO"
   },
   "source": [
    "#### 3.2.2 RouterRunnable\n",
    "\n",
    "多条件分支。\n",
    "\n",
    "\n",
    "比`RunnableBranch`更简洁的写法，同时也限制的输入参数的格式。\n",
    "\n",
    "\n",
    "输入参数必须是字典，有key和input两个键。`key`用来匹配条件，`input`则是匹配后，作为输出传递给相应的`Runnable`。\n",
    "\n",
    "这个更接近常见编程语言中的`switch`语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwTlqP1zHYBo",
    "outputId": "259e546e-de63-4e7a-df3f-75d0eed3e800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called x with input hello\n",
      "called y with input こんにちは\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.router import RouterRunnable\n",
    "\n",
    "router = RouterRunnable(\n",
    "    runnables={\n",
    "        \"x\": RunnableLambda(lambda i: f\"called x with input {i}\"),\n",
    "        \"y\": RunnableLambda(lambda i: f\"called y with input {i}\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(router.invoke({\"key\": \"x\", \"input\": \"hello\"}))\n",
    "print(router.invoke({\"key\": \"y\", \"input\": \"こんにちは\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVkz2E46MhNh"
   },
   "source": [
    "### 3.3 集合类型-字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlHUpw36-27j"
   },
   "source": [
    "#### 3.3.1 RunnablePassthrough\n",
    "\n",
    "任意输入都原文返回的`Runnable`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBSCdoFF_Dxd",
    "outputId": "a33ada76-9d43-4d22-f41e-43fd226cbe8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "print(passthrough.invoke(1))\n",
    "print(passthrough.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZfYeYZvACO1"
   },
   "source": [
    "#### 3.3.2 RunnableAssign\n",
    "\n",
    "追加新的字段。如果字段存在，则会覆盖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itxBTUWbALMp",
    "outputId": "0f1a212f-765a-4c16-f867-0f046d207373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 100, 'x': {'human': 100}}\n",
      "{'human': 'hello', 'x': {'human': 'hello'}}\n",
      "{'human': 'hello'}\n",
      "{'x': {'x': 'hello'}}\n",
      "{'x': 'hello'}\n",
      "The input to RunnablePassthrough.assign() must be a dict.\n",
      "{'input': 'Input >> hello'}\n",
      "{'input': 'Input >> hello', 'output': 'Output >> Input >> hello'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableAssign, RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# （非推荐）直接实例化一个RunnableAssign\n",
    "assign = RunnableAssign({\"x\": RunnablePassthrough()})\n",
    "print(assign.invoke({\"human\": 100}))\n",
    "\n",
    "# 添加字段并不会修改原来的字典，而是会生成新的字典\n",
    "dic = {\"human\": \"hello\"}\n",
    "print(assign.invoke(dic))\n",
    "print(dic)\n",
    "\n",
    "dic = {\"x\": \"hello\"}\n",
    "print(assign.invoke(dic))  # 新字典中，x: 'hello' 会被覆盖，但原dic不变\n",
    "print(dic)\n",
    "\n",
    "# RunnableAssign的输入参数必须是字典，否则是无法添加字段的\n",
    "try:\n",
    "    print(assign.invoke(2))\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "# 常见写法是在Runnable的基础上调用assign方法\n",
    "## 先创建一个Runnable\n",
    "runnable = RunnableLambda(lambda x: {\"input\": f\"Input >> {x}\"})\n",
    "print(runnable.invoke(\"hello\"))\n",
    "## 调用assign方法生成RunnableAssign\n",
    "runnable1 = runnable.assign(output=lambda dic: f'Output >> {dic[\"input\"]}')\n",
    "print(runnable1.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PVka1j-Csii"
   },
   "source": [
    "#### 3.3.3 RunnablePick\n",
    "\n",
    "字典中取出字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udNN92PlC2rT",
    "outputId": "61e11ad6-2ec9-47e2-c27a-df8af85b4bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 'hi'}\n",
      "None\n",
      "hi\n",
      "None\n",
      "The input to RunnablePassthrough.assign() must be a dict.\n",
      "{'human': 'hi', 'extra': 'dummy', 'test': 6}\n",
      "{'human': 'hi'}\n",
      "{'test': 6}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnablePick\n",
    "\n",
    "# 取出来部分字段，构成新的字典\n",
    "runnable1 = RunnablePick([\"human\"])\n",
    "print(runnable1.invoke({\"human\": \"hi\", \"extra\": \"dummy\"}))  # {'human': 'hi'}\n",
    "print(runnable1.invoke({\"no\": \"hi\", \"extra\": \"dummy\"}))  # 不存在则返回None\n",
    "\n",
    "# 取出某个字段的值\n",
    "runnable2 = RunnablePick(\"human\")\n",
    "print(runnable2.invoke({\"human\": \"hi\", \"extra\": \"dummy\"}))  # hi\n",
    "print(runnable2.invoke({\"no\": \"hi\", \"extra\": \"dummy\"}))  # 不存在则返回None\n",
    "\n",
    "# 注意，输入参数也必须是字典才行，否则是没法从字典里面取值的。\n",
    "try:\n",
    "    print(runnable2.invoke(2))\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "def modify(dic):\n",
    "    dic[\"test\"] = 6\n",
    "    return dic\n",
    "\n",
    "\n",
    "runnable3 = RunnableLambda(modify)\n",
    "print(runnable3.invoke({\"human\": \"hi\", \"extra\": \"dummy\"}))\n",
    "runnable4 = runnable3.pick([\"human\"])\n",
    "print(runnable4.invoke({\"human\": \"hi\", \"extra\": \"dummy\"}))\n",
    "runnable5 = runnable3.pick([\"test\"])\n",
    "print(runnable5.invoke({\"human\": \"hi\", \"extra\": \"dummy\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWSrL6M0LdWx"
   },
   "source": [
    "### 3.4 集合类型-列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh0rKVBKgDc0"
   },
   "source": [
    "#### 3.4.1 RunnableEachBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PswsPsEkzayv"
   },
   "source": [
    "##### RunnableEach\n",
    "\n",
    "处理列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8VK83Cxzi1t",
    "outputId": "dccbb499-f0dc-4733-9328-357c647f19a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello', id='run-7378a92b-c734-4265-b524-3fd66d3131ab-0'),\n",
       " AIMessage(content='How are you?', id='run-3668a7d8-88e4-4cb4-bee7-10a0b51a0306-0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableEach\n",
    "\n",
    "each = RunnableEach(bound=chat)\n",
    "each.invoke([\"hello\", \"good morning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gwhvbNJNHud"
   },
   "source": [
    "### 3.5 异常处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DUvjzGiltK2"
   },
   "source": [
    "#### 3.5.1 RunnableWithFallbacks\n",
    "\n",
    "异常处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhVkLMjEl4YO",
    "outputId": "ae659982-921a-4b9f-d53e-b9c7386e90d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fallback with:hi\n",
      "fallback with:{'question': 'hi', 'err': Exception('Dummy')}\n",
      "Dummy 没有被fallback捕获\n",
      "fallback2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def raise_exception(*args):\n",
    "    raise Exception(\"Dummy\")\n",
    "\n",
    "\n",
    "runnable = RunnableLambda(raise_exception).with_fallbacks(\n",
    "    [RunnableLambda(lambda x: \"fallback with:\" + str(x))]\n",
    ")\n",
    "print(\n",
    "    runnable.invoke(\"hi\")\n",
    ")  # 注意，默认传递给fallback的值，不是Exception，而是原来Runnable的输入值\n",
    "\n",
    "# 但是，可以使用exception_key来捕获异常，传递给fallback。注意，此时输入值必须为字典，否则exception_key添加到哪里呢？\n",
    "runnable = RunnableLambda(raise_exception).with_fallbacks(\n",
    "    [RunnableLambda(lambda x: \"fallback with:\" + str(x))], exception_key=\"err\"\n",
    ")\n",
    "print(runnable.invoke({\"question\": \"hi\"}))\n",
    "\n",
    "# 还可以控制捕获的异常类型\n",
    "try:\n",
    "    runnable = RunnableLambda(raise_exception).with_fallbacks(\n",
    "        [RunnableLambda(lambda x: \"fallback with:\" + str(x))],\n",
    "        exception_key=\"err\",\n",
    "        exceptions_to_handle=(OSError,),\n",
    "    )\n",
    "    print(runnable.invoke({\"question\": \"hi\"}))\n",
    "except Exception as e:\n",
    "    print(str(e) + \" 没有被fallback捕获\")\n",
    "\n",
    "\n",
    "runnable_2nd_fallback = RunnableLambda(raise_exception).with_fallbacks(\n",
    "    [\n",
    "        RunnableLambda(raise_exception),\n",
    "        RunnableLambda(lambda x: \"fallback2\"),\n",
    "        RunnableLambda(raise_exception),\n",
    "    ]\n",
    ")\n",
    "print(runnable_2nd_fallback.invoke(\"hello\"))\n",
    "\n",
    "\n",
    "# 注意：如果fallback无法处理异常，即fallback中仍然抛出异常，\n",
    "# 那么最终抛出的异常是原Runnable的，而不是fallback的\n",
    "def raise_1(*args):\n",
    "    raise Exception(\"1\")\n",
    "\n",
    "\n",
    "def raise_2(*args):\n",
    "    raise Exception(\"2\")\n",
    "\n",
    "\n",
    "def raise_3(*args):\n",
    "    raise Exception(\"3\")\n",
    "\n",
    "\n",
    "runnable_all_error = RunnableLambda(raise_1).with_fallbacks(\n",
    "    [RunnableLambda(raise_2), RunnableLambda(raise_3)]\n",
    ")\n",
    "try:\n",
    "    runnable_all_error.invoke(\"hello\")\n",
    "except Exception as e:\n",
    "    print(e)  # 不是2，不是3，而是1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbXIUpcgcoay"
   },
   "source": [
    "fallback只能抛出原来的runnable的异常，如果想在fallback中重新抛出新的异常怎么办？ 用Python的`try-except-finally`和`RunnableLambda`实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zmrX9E0c69f",
    "outputId": "33c213ce-9aa5-4f33-e9c3-6ebaca608b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from chain3: 1 < 3\n",
      "from chain2: 2 < 5\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def raise_1(n):\n",
    "    if n < 7:\n",
    "        raise Exception(f\"{n} < 7\")\n",
    "    return n\n",
    "\n",
    "\n",
    "chain1 = RunnableLambda(raise_1)\n",
    "\n",
    "\n",
    "def raise_2(n):\n",
    "    if n < 5:\n",
    "        raise Exception(f\"{n} < 5\")\n",
    "    return n\n",
    "\n",
    "\n",
    "chain2 = RunnableLambda(raise_2)\n",
    "\n",
    "\n",
    "def raise_3(n):\n",
    "    if n < 3:\n",
    "        raise Exception(f\"{n} < 3\")\n",
    "    return n\n",
    "\n",
    "\n",
    "chain3 = RunnableLambda(raise_3)\n",
    "\n",
    "\n",
    "def full(n):\n",
    "    try:\n",
    "        return chain1.invoke(n)\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            return chain2.invoke(n)\n",
    "        except Exception as e2:\n",
    "            if n < 2:\n",
    "                try:\n",
    "                    return chain3.invoke(n)\n",
    "                except Exception as e3:\n",
    "                    raise Exception(\"from chain3: \" + str(e3))\n",
    "            raise Exception(\"from chain2: \" + str(e2))\n",
    "        raise Exception(\"from chain1: \" + str(e1))\n",
    "\n",
    "\n",
    "fullchain = RunnableLambda(full)\n",
    "\n",
    "try:\n",
    "    print(fullchain.invoke(1))\n",
    "except Exception as e:\n",
    "    print(e)  # 此处是raise_3的异常时，重新raise的异常\n",
    "\n",
    "try:\n",
    "    print(fullchain.invoke(2))\n",
    "except Exception as e:\n",
    "    print(e)  # 此处是raise_2的异常时，重新raise的异常"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLZ0PHniN4q0"
   },
   "source": [
    "### 3.6 动态链"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jucPC14RhO0B"
   },
   "source": [
    "#### 3.6.1 DynamicRunnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNFF8QD8hWJ0"
   },
   "source": [
    "##### RunnableConfigurableAlternatives\n",
    "\n",
    "为链添加可供设置的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJc-h2D3h2p1",
    "outputId": "e058f9d0-2b8d-43cf-e85e-4550f50b7948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好' id='run-d3078158-63a2-4988-844e-b7b918a65a4f-0'\n",
      "content='hello' id='run-685dae3e-ba5b-4ba6-9f9a-308721efeab0-0'\n",
      "content='こんにちは' id='run-2bb03494-0766-4705-a633-e5badf9b91d9-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import ConfigurableField, RunnableLambda\n",
    "from langchain_core.runnables.configurable import RunnableConfigurableAlternatives\n",
    "\n",
    "chain1 = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"你好\",\n",
    "    ]\n",
    ")\n",
    "chain2 = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"hello\",\n",
    "    ]\n",
    ")\n",
    "chain3 = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"こんにちは\",\n",
    "    ]\n",
    ")\n",
    "# Add a new config \"mode\" with key in ['default', 'en', 'jp']\n",
    "chain_configured = chain1.configurable_alternatives(\n",
    "    ConfigurableField(id=\"mode\"), default_key=\"default\", en=chain2, jp=chain3\n",
    ")\n",
    "\n",
    "isinstance(chain_configured, RunnableConfigurableAlternatives)\n",
    "\n",
    "# switch model demo\n",
    "chain_configured.invoke(\"hello\")\n",
    "\n",
    "\n",
    "print(chain_configured.with_config(configurable={\"mode\": \"default\"}).invoke(\"\"))\n",
    "\n",
    "print(chain_configured.with_config(configurable={\"mode\": \"en\"}).invoke(\"\"))\n",
    "\n",
    "print(chain_configured.with_config(configurable={\"mode\": \"jp\"}).invoke(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfpCsgDTj_CN"
   },
   "source": [
    "##### RunnableConfigurableFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86Ujwj3NkGko",
    "outputId": "45aea991-d981-4f35-e855-21e85d995f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'cache', 'verbose', 'callbacks', 'tags', 'metadata', 'custom_get_token_ids', 'callback_manager', 'responses', 'sleep', 'i'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好', id='run-553210c2-d851-4ddb-b8e7-aa6237d82f1f-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import ConfigurableField, RunnableLambda\n",
    "from langchain_core.runnables.configurable import RunnableConfigurableAlternatives\n",
    "\n",
    "chat = FakeListChatModel(\n",
    "    responses=[\n",
    "        \"你好\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat.__fields__.keys())\n",
    "\n",
    "chat.configurable_fields(responses=ConfigurableField(id=\"responses\")).with_config(\n",
    "    responses=[\"xxxxxx\"]\n",
    ").invoke(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXZJHLjGNQr1"
   },
   "source": [
    "### 3.7 其它高级用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo-l9IUUgRa1"
   },
   "source": [
    "#### 3.7.1 RunnableBindingBase\n",
    "\n",
    "以委托的方式，通过`kwargs`为既存的`Runnable`添加功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNT27nPlOico",
    "outputId": "856c0e87-986c-4874-f932-f45463cdd491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Type, get_args\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.base import RunnableBindingBase\n",
    "\n",
    "\n",
    "# 首先，使用RunnableLambda创建一个底层的Runnbale。\n",
    "def plus3(*args: Any, **kwargs: Any) -> int:\n",
    "    return 3 + kwargs.get(\"n\", 0)\n",
    "\n",
    "\n",
    "runnable = RunnableLambda(plus3)\n",
    "\n",
    "\n",
    "# 然后，这是一个可以向Runnable的kwargs中添加 n 的Runnable。\n",
    "class CustomRunnableBinding(RunnableBindingBase):\n",
    "\n",
    "    def set_custom_number(self, n):\n",
    "        self.kwargs.update(n=n)\n",
    "\n",
    "\n",
    "# 创建一个Runnable实例\n",
    "runnable1 = CustomRunnableBinding(bound=runnable)\n",
    "## 设定kwargs\n",
    "runnable1.set_custom_number(7)\n",
    "## 在RunnableBindingBase的invoke逻辑中，kwargs被传递给invoke了\n",
    "print(runnable1.invoke({}))  # 因此，相当于 runnable.invoke({}, n = 7)\n",
    "\n",
    "print(runnable.invoke({}, n=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcIMHA6z7MGF"
   },
   "source": [
    "#### 3.7.2 RunnableBinding\n",
    "\n",
    "与`RunnableBindingBase`相比，提供了更简单的设定方法：直接通过构造函数指定`kwargs`即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p40C5xMS7V2w",
    "outputId": "c2885069-71aa-4aad-944b-90809c8f4d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "7\n",
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "start\n",
      "end\n",
      "3\n",
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Type, get_args\n",
    "\n",
    "from langchain_core.runnables import RunnableBinding, RunnableLambda\n",
    "\n",
    "\n",
    "def plus3(*args: Any, **kwargs: Any) -> int:\n",
    "    return 3 + kwargs.get(\"n\", 0)\n",
    "\n",
    "\n",
    "runnable = RunnableLambda(plus3)\n",
    "print(runnable.invoke({}, n=4))  # 7\n",
    "\n",
    "# （非推荐）直接实例化\n",
    "runnable1 = RunnableBinding(bound=runnable, kwargs={\"n\": 4})  # 直接指定kwargs\n",
    "\n",
    "print(runnable1.invoke({}))  # 7\n",
    "\n",
    "# 推荐用法: Runnable基类的bind方法，其实就是调用RunnableBinding构造函数\n",
    "\n",
    "## kwargs\n",
    "runnable2 = runnable.bind(n=4)\n",
    "print(type(runnable2))\n",
    "print(runnable2.invoke({}))  # 7\n",
    "\n",
    "# 除了kwargs以外，还有config, callback, types等可以设定\n",
    "## config\n",
    "\n",
    "## callback\n",
    "runnable4 = runnable.with_listeners(\n",
    "    on_start=lambda _: print(\"start\"), on_end=lambda _: print(\"end\")\n",
    ")\n",
    "print(type(runnable4))\n",
    "print(runnable4.invoke({}))  # 3\n",
    "\n",
    "## with_types\n",
    "runnable5 = runnable.with_types(input_type=int)\n",
    "print(type(runnable5))\n",
    "print(runnable5.invoke({}))  # 3\n",
    "\n",
    "echo = RunnableLambda(lambda x: \"Input is\" + x).with_types(output_type=str)\n",
    "\n",
    "test = echo | runnable5\n",
    "\n",
    "print(test.invoke(\"7\"))  # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71PhJR6vur_z"
   },
   "source": [
    "#### 3.7.3 RunnableWithMessageHistory\n",
    "\n",
    "将`Runnable`给包装一层，添加历史记录管理功能。\n",
    "\n",
    "\n",
    "首先，需要一个会话管理的函数，通过`get_session_history`可以根据会话ID取出该会话的历史记录管理部品（`BaseChatMessageHistory`，可以通过它在会话中查找消息，或向会话中添加消息）。相当于一个历史记录管理部品的工厂。\n",
    "\n",
    "\n",
    "历史记录管理部品有以下接口：\n",
    "\n",
    "- add_messages/aadd_messages: 向历史记录中批量添加消息\n",
    "- messages/aget_messages: 取出所有历史记录\n",
    "- clear/aclear: 清空历史记录\n",
    "\n",
    "\n",
    "其次，被包装的`Runnable`应该满足以下条件：\n",
    "\n",
    "*   输入\n",
    "    * BaseMessage列表\n",
    "    * 字典，其中指定key为所有消息的BaseMessage列表\n",
    "    * 字典，其中一个key为最新的一条消息的字符串/BaseMessage/BaseMessage列表，另一个key为历史记录消息BaseMessage列表\n",
    "       * 最新一条消息为字符串的话，自动被当作HumanMessage\n",
    "*   输出\n",
    "    * 作为AIMessage内容的字符串\n",
    "    * 一条BaseMessage或 BaseMessage列表\n",
    "    * 字典，其中指定key为一条BaseMessage或 BaseMessage列表\n",
    "\n",
    "\n",
    "另外，与输出输出相关的三个比较重要的参数：\n",
    "- input_messages_key：输入为字典时，必须指定该参数，取出消息或消息列表\n",
    "- output_messages_key：输出为字典时，必须指定该参数，取出消息或消息列表\n",
    "- history_messages_key：输入为字典，且历史记录使用单独的key管理时，必须指定该参数\n",
    "\n",
    "\n",
    "主要逻辑就是:\n",
    "\n",
    "```python\n",
    "# 取出历史记录\n",
    "history_chain: Runnable = RunnableLambda(\n",
    "    self._enter_history, self._aenter_history\n",
    ").with_config(run_name=\"load_history\")\n",
    "# 如果runnable需要的输入是字典的话，稍微调整一下格式\n",
    "messages_key = history_messages_key or input_messages_key\n",
    "if messages_key:\n",
    "    history_chain = RunnablePassthrough.assign(\n",
    "        **{messages_key: history_chain}\n",
    "    ).with_config(run_name=\"insert_history\")\n",
    "\n",
    "# 历史记录传递给runnable执行，并且执行完时，触发_exit_history方法，更新保存历史记录\n",
    "bound = (\n",
    "    history_chain | runnable.with_listeners(on_end=self._exit_history)\n",
    ").with_config(run_name=\"RunnableWithMessageHistory\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL4aXE7CuzpM",
    "outputId": "29310a52-b8cc-4234-df6e-f82804af2d26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 185c2f68-3061-45cb-b7a3-0b3f68f71c35 not found for run 2254beb4-56d9-435c-a3b0-4befa0a959ff. Treating as a root run.\n",
      "Parent run 258cdf03-9cbf-4054-abfa-cb5d119785db not found for run 60e98539-02a2-4bf3-a754-b6804045ef88. Treating as a root run.\n",
      "Parent run b699011a-37d5-4a19-b1ef-aaeecb0c1b40 not found for run 166e68a3-d8fc-442a-a75f-892de913bcaa. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='echo 1' id='run-0ff4fba1-ccdb-426f-a6c1-9f89d2c2f13e-0'\n",
      "content='add 1 to the previous number' id='run-63477712-68fc-4b59-92e3-cd79447fd3ab-0'\n",
      "content='add 1 to the previous number' id='run-e9066462-1d86-40ae-b3cc-e22d67884fc8-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 014ec37a-9146-422c-ab01-b47cca11f2d8 not found for run 770a6508-3a6b-446b-9949-5b653a382d7c. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='add 1 to the previous number' id='run-71189361-0243-4242-8f15-65b4b18aa567-0'\n",
      "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='echo 1'), HumanMessage(content='echo 1', id='run-0ff4fba1-ccdb-426f-a6c1-9f89d2c2f13e-0'), HumanMessage(content='add 1 to the previous number'), HumanMessage(content='add 1 to the previous number', id='run-63477712-68fc-4b59-92e3-cd79447fd3ab-0'), HumanMessage(content='add 1 to the previous number'), HumanMessage(content='add 1 to the previous number', id='run-e9066462-1d86-40ae-b3cc-e22d67884fc8-0'), HumanMessage(content='add 1 to the previous number'), HumanMessage(content='add 1 to the previous number', id='run-71189361-0243-4242-8f15-65b4b18aa567-0')])}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.language_models.fake_chat_models import ParrotFakeChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 会话存储位置\n",
    "global_store = {}\n",
    "\n",
    "\n",
    "# 根据会话ID，创建或返回既有的历史记录管理部品\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in global_store:\n",
    "        # 历史记录管理使用InMemoryChatMessageHistory\n",
    "        global_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return global_store[session_id]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [MessagesPlaceholder(variable_name=\"history\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "# 模拟一个LLM，单纯将用户的输入原文返回的\n",
    "chat = ParrotFakeChatModel()\n",
    "\n",
    "# add a memory to a chain with prompt and chat\n",
    "chat_with_memory: Runnable = RunnableWithMessageHistory(\n",
    "    prompt | chat,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "res = chat_with_memory.invoke(\n",
    "    {\"input\": \"echo 1\"}, config={\"configurable\": {\"session_id\": \"abc123\"}}\n",
    ")\n",
    "print(res)\n",
    "\n",
    "res = chat_with_memory.invoke(\n",
    "    {\"input\": \"add 1 to the previous number\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(res)\n",
    "\n",
    "res = chat_with_memory.invoke(\n",
    "    {\"input\": \"add 1 to the previous number\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(res)\n",
    "\n",
    "res = chat_with_memory.invoke(\n",
    "    {\"input\": \"add 1 to the previous number\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(res)\n",
    "\n",
    "print(global_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWOgcyHmEz7w"
   },
   "source": [
    "###### RunnableRetry\n",
    "\n",
    "失败时重试。可以设定失败次数，当哪些异常出现时进行重试等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZpxVixHE6kD",
    "outputId": "1a7816e0-09b9-484d-faf2-8611ff000e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "self.c = 1 < 2\n",
      "called\n",
      "self.c = 2 < 2\n",
      "called\n",
      "success\n",
      "called\n",
      "called\n",
      "called\n",
      "success\n",
      "called\n",
      "called\n",
      "called\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "class SuccessAfter2:\n",
    "    def __init__(self):\n",
    "        self.c = 0\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print(\"called\")\n",
    "        if self.c < 2:\n",
    "            self.c += 1\n",
    "            raise ValueError(f\"self.c = {self.c} < 2\")\n",
    "        return \"success\"\n",
    "\n",
    "\n",
    "from langchain_core.runnables.retry import RunnableRetry\n",
    "\n",
    "# Without Retry\n",
    "runnable = RunnableLambda(SuccessAfter2())\n",
    "\n",
    "try:\n",
    "    runnable.invoke(None)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    try:\n",
    "        runnable.invoke(None)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        res = runnable.invoke(None)\n",
    "        print(res)\n",
    "\n",
    "\n",
    "# With retry\n",
    "runnable_with_retry = RunnableRetry(\n",
    "    bound=RunnableLambda(SuccessAfter2()),\n",
    "    max_attempt_number=3,  # How many times to retry ?\n",
    "    retry_exception_types=(ValueError,),  # Which exceptions will be retried?\n",
    ")\n",
    "print(runnable_with_retry.invoke(None))\n",
    "\n",
    "# 更常见的写法\n",
    "runnable = RunnableLambda(SuccessAfter2())\n",
    "runnable_with_retry = runnable.with_retry(\n",
    "    stop_after_attempt=3, retry_if_exception_type=(ValueError,)\n",
    ")\n",
    "print(runnable_with_retry.invoke(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDU6bA6fRV98"
   },
   "source": [
    "### 3.8 其它Langchain概念\n",
    "\n",
    "基本结构就是“构造输入数据-->LLM模型-->解析输出结果”\n",
    "\n",
    "`Prompot | Model | OutputParser`\n",
    "\n",
    "特别的，`Retriever`也借用了`Runnable`的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9agp7OFBSCFb"
   },
   "source": [
    "#### 3.8.1 BaseLanguageModel\n",
    "\n",
    "继承自`RunnableSerializable`。大语言模型的基类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSRkoshRBmCv",
    "outputId": "aa60d1ca-2b1a-474f-c0c5-43a94590a311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Sequence\n",
    "\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "from langchain_core.prompt_values import PromptValue\n",
    "\n",
    "\n",
    "class MyLLM(BaseLanguageModel):\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    mock_output: str\n",
    "\n",
    "    def __init__(self, mock_output: str):\n",
    "        super(MyLLM, self).__init__(mock_output=mock_output)\n",
    "\n",
    "    async def agenerate_prompt(self, *args, **kwargs) -> LLMResult:\n",
    "        return LLMResult(generations=[[Generation(text=self.mock_output)]])\n",
    "\n",
    "    def generate_prompt(self, *args, **kwargs) -> LLMResult:\n",
    "        return LLMResult(generations=[[Generation(text=self.mock_output)]])\n",
    "\n",
    "    async def apredict(self, *args, **kwargs) -> str:\n",
    "        return self.mock_output\n",
    "\n",
    "    def predict(self, *args, **kwargs) -> str:\n",
    "        return self.mock_output\n",
    "\n",
    "    async def apredict_messages(self, *args, **kwargs) -> BaseMessage:\n",
    "        return BaseMessage(self.mock_output)\n",
    "\n",
    "    def predict_messages(self, *args, **kwargs) -> BaseMessage:\n",
    "        return BaseMessage(self.mock_output)\n",
    "\n",
    "    def invoke(self, *args, **kwargs) -> str:\n",
    "        return self.mock_output\n",
    "\n",
    "\n",
    "llm = MyLLM(mock_output=\"输出\")\n",
    "\n",
    "print(llm.predict(\"测试\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBpB77GPGyiK"
   },
   "source": [
    "`BaseLanguageModel`有两个子类，对应两种模式：LLM 和 聊天模式。\n",
    "\n",
    "- `BaseLLM`：LLM 指的是纯文本 I/O 的模型，其包装的 API 将字符串提示作为输入，并输出字符串。\n",
    "- `BaseChatModel`：聊天模型通常由 LLM 支持，但专门针对对话进行了调整，其 API 采用聊天消息列表作为输入，而不是单个字符串。通常，这些消息都标有角色（例如，“System”，“AI”，“Human”）。聊天模型会返回一条 AI 聊天消息作为输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nfz3tNKSe4_"
   },
   "source": [
    "##### BaseChatModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pepDFa9wHCrm"
   },
   "source": [
    "##### BaseLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P39cFVxGSwkv"
   },
   "source": [
    "#### 3.8.2 BasePromptTemplate\n",
    "\n",
    "继承自` RunnableSerializable`。Prompt模板的基类。\n",
    "\n",
    "模板是一个构建prompt的可执行模块。它的输入是变量，输出是替换后得到的prompt。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHdi3GkJmfzY"
   },
   "source": [
    "##### BaseChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeBwlBHoToZz"
   },
   "source": [
    "#### 3.8.3 BaseOutputParser\n",
    "\n",
    "继承自`BaseLLMOutputParser`和`RunnableSerializable`。结果解析器的基类。\n",
    "\n",
    "- `BaseLLMOutputParser`定义了解析函数的接口\n",
    "- `RunnableSerializable`保证了可以链式串接的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIhIZZKKH0kQ",
    "outputId": "eb1cadce-3088-4111-83e8-dca213a5aafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C']\n",
      "['1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "\n",
    "result = CommaSeparatedListOutputParser().parse(\"A, B, C\")\n",
    "print(result)\n",
    "\n",
    "chain = RunnableLambda(lambda x: x) | CommaSeparatedListOutputParser()\n",
    "\n",
    "print(chain.invoke(\"1, 2, 3, 4, 5, 6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvpgEh3HJJUW",
    "outputId": "1db20229-f468-4e49-e5b3-21c61c04be62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    true_val: str = \"YES\"\n",
    "    false_val: str = \"NO\"\n",
    "\n",
    "    def parse(self, text: str) -> bool:\n",
    "        cleaned_text = text.strip().upper()\n",
    "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
    "            raise OutputParserException(\n",
    "                f\"BooleanOutputParser expected output value to either be \"\n",
    "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
    "                f\"Received {cleaned_text}.\"\n",
    "            )\n",
    "        return cleaned_text == self.true_val.upper()\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"boolean_output_parser\"\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough() | BooleanOutputParser()\n",
    "\n",
    "print(chain.invoke(\"NO\"))\n",
    "print(chain.invoke(\"YES\"))\n",
    "print(chain.invoke(\"Yes\"))\n",
    "print(chain.invoke(\"No\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEhf03LkRcgv"
   },
   "source": [
    "#### 3.8.4 BaseRetriever\n",
    "\n",
    "继承自`RunnableSerializable`。检索器的基类。\n",
    "\n",
    "检索器借用了`Runnable`的概念。它是一个特殊的`Runnable`，输入为字符串，输出为`Document`列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UZQyp5M0-Cz",
    "outputId": "618dcffa-a9cb-41fd-c7c5-34d471eccf8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1.Introduction'\n",
      "page_content='2.Basic'\n",
      "page_content='3.Design'\n",
      "page_content='4.Implementation'\n",
      "page_content='5.Test'\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "\n",
    "class SimpleRetriever(BaseRetriever):\n",
    "    docs: List[Document]\n",
    "    k: int = 5\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Return the first k documents from the list of documents\"\"\"\n",
    "        return self.docs[: self.k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"(Optional) async native implementation.\"\"\"\n",
    "        return self.docs[: self.k]\n",
    "\n",
    "\n",
    "retriever = SimpleRetriever(\n",
    "    docs=[\n",
    "        Document(page_content=\"1.Introduction\"),\n",
    "        Document(page_content=\"2.Basic\"),\n",
    "        Document(page_content=\"3.Design\"),\n",
    "        Document(page_content=\"4.Implementation\"),\n",
    "        Document(page_content=\"5.Test\"),\n",
    "        Document(page_content=\"6.Conclusion\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "documents = retriever.invoke(\"任意问题\")\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
