{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f20cee2-9025-49ab-936f-9cfb5426fe85",
   "metadata": {},
   "source": [
    "# ä¾‹. å¤šåœºæ™¯å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d59ef80-ec0f-4dde-95f5-fa8a33a5c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "import json\n",
    "\n",
    "def show_documents(docs: list[Document]):\n",
    "    from IPython.display import HTML, display\n",
    "    html = \"\"\n",
    "    html += \"<ul style=\\\"list-style: none;\\\">\"\n",
    "    for doc in docs:\n",
    "      html += \"<li><div style=\\\"margin: 15px 0;  box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2); transition: 0.3s;\\\">\"\n",
    "      html+=f\"<pre style=\\\"background-color: #eee; font-size: 10px; border: 1px dashed #ccc; padding: 5px;\\\">{json.dumps(doc.metadata, indent=2, ensure_ascii=False)}</pre>\"\n",
    "      html+=f\"<pre style=\\\"background-color: #eff; padding: 5px;\\\">{doc.page_content}</pre>\"\n",
    "      html+=\"</div></li>\"\n",
    "    html += \"</ul>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "def show_messages(messages: list[BaseMessage]):\n",
    "    from IPython.display import HTML, display\n",
    "    html = \"\"\n",
    "    html += \"<ul style=\\\"list-style: none; margin: 5px 0;\\\">\"\n",
    "    for msg in messages:\n",
    "      html += \"<li><div style=\\\"margin: 15px 5px;\\\">\"\n",
    "      match msg.type:\n",
    "        case \"ai\":\n",
    "            html += \"<div style=\\\"text-align: right; font-size: 24px;\\\">ğŸ¤–</div>\"\n",
    "            html+=f\"<pre style=\\\"background-color: #eff; float: right; padding: 5px; width: fit-content; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2); transition: 0.3s;   border-radius: 5px;\\\">{msg.content}</pre>\"\n",
    "        case \"human\":\n",
    "            html += \"<div style=\\\"text-align: left;font-size: 24px;\\\">ğŸ‘¨ğŸ»</div>\"\n",
    "            html+=f\"<pre style=\\\"background-color: #ffe; padding: 5px; width: fit-content; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2); transition: 0.3s; border-radius: 5px;\\\">{msg.content}</pre>\"\n",
    "        case _:\n",
    "            html += f\"<div style=\\\"text-align: left;font-size: 24px;\\\">{msg.type}</div>\"\n",
    "            html+=f\"<pre style=\\\"background-color: #eee; padding: 5px;width: fit-content; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2); transition: 0.3s;\\\">{msg.content}</pre>\"\n",
    "      html+=\"</div></li>\"\n",
    "    html += \"</ul>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "def show_answer(message: AIMessage):\n",
    "    from IPython.display import HTML, display\n",
    "    html = \"\"\n",
    "    html += \"<div style=\\\"background-color: #eee; padding: 5px;\\\">\"\n",
    "    html += f\"<div style=\\\"font-size: 9px; color: #333;\\\">id={message.id}</div>\"\n",
    "    html += f\"<pre style=\\\"background-color: transparent; border: 1px dash #ccc; padding: 5px; width: fit-content;\\\">{message.content}</pre>\"\n",
    "    html += f\"<pre style=\\\"font-size: 9px;\\\">{json.dumps(message.response_metadata, indent=2)}</pre>\"\n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219fdbc8-eb32-4c7c-9ee7-2f3a65c8ff2f",
   "metadata": {},
   "source": [
    "## 1. åœºæ™¯åˆ¤å®š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b13fdc-9e61-425b-8fe8-6fdcba915332",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œå®šä¹‰å„ç§åœºæ™¯çš„åˆ¤å®šç”¨æç¤ºæ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c502d5-f327-423a-b83a-47e73f022d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #eee; padding: 5px;\"><div style=\"font-size: 9px; color: #333;\">id=run-fec4af2d-9843-4247-927a-29c1f83c3283-0</div><pre style=\"background-color: transparent; border: 1px dash #ccc; padding: 5px; width: fit-content;\">OK</pre><pre style=\"font-size: 9px;\">{\n",
       "  \"token_usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 120,\n",
       "    \"total_tokens\": 121\n",
       "  },\n",
       "  \"model_name\": \"gpt-4\",\n",
       "  \"system_fingerprint\": null,\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"logprobs\": null\n",
       "}</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #eee; padding: 5px;\"><div style=\"font-size: 9px; color: #333;\">id=run-d8e4b39a-7da5-434f-b67b-a976f2923de2-0</div><pre style=\"background-color: transparent; border: 1px dash #ccc; padding: 5px; width: fit-content;\">NG</pre><pre style=\"font-size: 9px;\">{\n",
       "  \"token_usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 120,\n",
       "    \"total_tokens\": 121\n",
       "  },\n",
       "  \"model_name\": \"gpt-4\",\n",
       "  \"system_fingerprint\": null,\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"logprobs\": null\n",
       "}</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INTENTS = [\n",
    "    \"get_weather\",\n",
    "    \"current_time\",\n",
    "    \"ask_question_about_rgs\",\n",
    "]\n",
    "\n",
    "ask_question_about_rgs_system_prompt = (\n",
    "    \"You are a content filter for given inputs about asking qustions with RGS Information System Co., Ltd (Japanese: å…­å…ƒç´ æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ æ ªå¼ä¼šç¤¾. Chinese: å…­å…ƒç´ ç§‘æŠ€æœ‰é™å…¬å¸. ) . \\n\"\n",
    "    \"Only questions in following categories about this company are considered OK. Any other questions should be NG.\\n\"\n",
    "    \" - office regulations\\n\"\n",
    "    \" - news\\n\"\n",
    "    \" - recruitment information\\n\"\n",
    "    \" - introduction\\n\"\n",
    "    \" - access map/ address\\n\"\n",
    "    \" - products (ATgo, ITgo, Rakumon) information\\n\"\n",
    "    \" - organization information\\n\"\n",
    "    \"Please check whether the input from user is OK or NG according to EXAMPLES below. \\n\"\n",
    "    \"Please only ouput OK or NG without any explanation. \\n\\n\"\n",
    "    'EXAMPLES:\\n'\n",
    "    '# OK:\\n'\n",
    "    '- What is the meaning of RGS?\\n'\n",
    "    '- When does RGS established?\\n'\n",
    "    '- Where does RGS established?\\n'\n",
    "    '- What services are RGS provided? \\n'\n",
    "    '- Is RGS hiring IT Engineers this year?\\n'\n",
    "    '# NG:\\n'\n",
    "    '- Please show me the financial report of RGS.\\n'\n",
    "    '- Please show me the design documents about ATgo developed by RGS.'\n",
    ")\n",
    "\n",
    "get_weather_system_prompt = (\n",
    "    \"You are a content filter for given inputs about asking weather. \\n\"\n",
    "    \"Please check whether the input from user is OK or NG according to EXAMPLES below. \\n\"\n",
    "    \"Please only ouput OK or NG without any explanation. \\n\\n\"\n",
    "    'EXAMPLES:\\n'\n",
    "    '# OK:\\n'\n",
    "    '- What is the weather of tomorrow?\\n'\n",
    "    '- What is the weather of 1st, Sept. 2024?\\n'\n",
    "    '- Will it rain tomorrow?\\n'\n",
    "    '- What is the temperature of tomorrow? \\n'\n",
    "    '- Will it rain tomorrow in Tokyo?\\n'\n",
    "    '# NG:\\n'\n",
    "    '- What is now?\\n'\n",
    "    '- What is your name?'\n",
    ")\n",
    "\n",
    "current_time_system_prompt = (\n",
    "    \"You are a content filter for given inputs about asking current time. \\n\"\n",
    "    \"Please check whether the input from user is OK or NG according to EXAMPLES below. \\n\"\n",
    "    \"Please only ouput OK or NG without any explanation. \\n\\n\"\n",
    "    'EXAMPLES:\\n'\n",
    "    '# OK:\\n'\n",
    "    '- What is now?\\n'\n",
    "    '- Is it 1st, Sept. 2024, today?\\n'\n",
    "    '- What day of the week is it today?\\n'\n",
    "    '- Is it Tuesday today? \\n'\n",
    "    '# NG:\\n'\n",
    "    '- What is RGS?\\n'\n",
    "    '- What is your name?'\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", current_time_system_prompt),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"question\": \"ä½•æ›œæ—¥ã§ã™ã‹ï¼Ÿ\"\n",
    "})\n",
    "show_answer(res)\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"question\": \"ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ\"\n",
    "})\n",
    "show_answer(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb46ece-dec3-46ee-8b50-da7189119715",
   "metadata": {},
   "source": [
    "å°†ç»“æœå˜ä¸ºå¸ƒå°”å€¼ï¼Œéœ€è¦ä¸€ä¸ªè§£æå™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e154c748-3076-417f-9517-76e49db2bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from typing import Self\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def extract_words(sentences: str) -> list[str]:\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "     \n",
    "    word_tokens = word_tokenize(sentences)\n",
    "    # converts the words in word_tokens to lower case and then checks whether \n",
    "    #they are present in stop_words or not\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    #with no lower case conversion\n",
    "    filtered_sentence = []\n",
    "     \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "     \n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)\n",
    "\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "# The [bool] describes a parameterization of a generic.\n",
    "# It's basically indicating what the return type of parse is\n",
    "# in this case the return type is either True or False\n",
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    \"\"\"Custom boolean parser.\"\"\"\n",
    "\n",
    "    true_val: str = \"OK\"\n",
    "    false_val: str = \"NG\"\n",
    "\n",
    "    def parse(self: Self, text: str) -> bool:\n",
    "        cleaned_text = extract_words(text)\n",
    "        if (self.true_val not in cleaned_text) and (self.false_val not in cleaned_text):\n",
    "            msg = (\n",
    "                f\"BooleanOutputParser expected output value to either be \"\n",
    "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
    "                f\"Received {cleaned_text}.\"\n",
    "            )\n",
    "            raise OutputParserException(msg)\n",
    "        return self.true_val in cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self: Self) -> str:\n",
    "        return \"boolean_output_parser\"\n",
    "\n",
    "bool_parser = BooleanOutputParser()\n",
    "\n",
    "print(bool_parser.invoke(\"OK\"))\n",
    "print(bool_parser.invoke(\"NG\"))\n",
    "print(bool_parser.invoke(\"It is OK.\"))\n",
    "print(bool_parser.invoke(\"Sorry. The answer is NG.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad2633a-b18d-41bd-91e0-3586f21bf103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def sence_tester(sence: str, question: str):\n",
    "    match sence:\n",
    "        case \"get_weather\":\n",
    "            chain = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", get_weather_system_prompt),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]) | llm | BooleanOutputParser()\n",
    "        case \"current_time\":\n",
    "            chain = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", current_time_system_prompt),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]) | llm | BooleanOutputParser()\n",
    "        case \"ask_question_about_rgs\":\n",
    "            chain = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", ask_question_about_rgs_system_prompt),\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]) | llm | BooleanOutputParser()\n",
    "        case _:\n",
    "            chain = RunnableLambda(lambda _: False)\n",
    "    return chain.invoke(question)\n",
    "\n",
    "print(sence_tester(\"get_weather\", \"å›ã®åã¯ï¼Ÿ\"))\n",
    "print(sence_tester(\"get_weather\", \"ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470e8e6-236b-4272-83bc-06039de2660b",
   "metadata": {},
   "source": [
    "## 2. æ„å›¾æ£€æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542648b-b425-4d7e-ac08-51cccfb82a83",
   "metadata": {},
   "source": [
    "å¯¹äºæ„å›¾ä¸æ˜çš„ï¼Œåˆ™éœ€è¦æ£€æµ‹ç”¨æˆ·çš„æ„å›¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfad0cf-f9be-45b6-a7cb-fa3d6f2839d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: #eee; padding: 5px;\"><div style=\"font-size: 9px; color: #333;\">id=run-f2442a0b-22a7-41e8-a0bf-6f7d24495afc-0</div><pre style=\"background-color: transparent; border: 1px dash #ccc; padding: 5px; width: fit-content;\">{ \"intent\": \"current_time\", \"arguments\": {} }</pre><pre style=\"font-size: 9px;\">{\n",
       "  \"token_usage\": {\n",
       "    \"completion_tokens\": 13,\n",
       "    \"prompt_tokens\": 610,\n",
       "    \"total_tokens\": 623\n",
       "  },\n",
       "  \"model_name\": \"gpt-4\",\n",
       "  \"system_fingerprint\": null,\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"logprobs\": null\n",
       "}</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "\n",
    "import json\n",
    "\n",
    "INTENTS = [\n",
    "    \"get_weather\",\n",
    "    \"current_time\",\n",
    "    \"ask_question_about_rgs\",\n",
    "]\n",
    "\n",
    "def build_intent_classifier(intents=INTENTS):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Act as the intent classification component of a assistant, similar to Amazon Alexa \"\n",
    "        \"(except your name is 'Becca', not 'Alexa').\\n\"\n",
    "        'You receive input in json format: `{{\"input\":...}}`\\n'\n",
    "        'You respond in json format: `{{\"intent\":..., \"arguments\":{{ ... }}, }}}}`\\n\\n'\n",
    "        'NOTE: \\n'\n",
    "        '- If the input can not classified to given intents, take it as \"unclassified\".\\n\\n'\n",
    "    )\n",
    "\n",
    "    ask_question_about_rgs_prompt = (\n",
    "        \"[Intent Name]: ask_question_about_rgs\\n\"\n",
    "        \"[Definition]: The given inputs are about asking qustions with RGS Information System Co., Ltd (Japanese: å…­å…ƒç´ æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ æ ªå¼ä¼šç¤¾. Chinese: å…­å…ƒç´ ç§‘æŠ€æœ‰é™å…¬å¸. ) . \\n\"\n",
    "        \"Only questions in following categories about this company are considered OK. Any other questions should be NG.\\n\"\n",
    "        \" - office regulations\\n\"\n",
    "        \" - news\\n\"\n",
    "        \" - recruitment information\\n\"\n",
    "        \" - introduction\\n\"\n",
    "        \" - access map/ address\\n\"\n",
    "        \" - products (ATgo, ITgo, Rakumon) information\\n\"\n",
    "        \" - organization information\\n\"\n",
    "        \"You can follow to EXAMPLES below. \\n\"\n",
    "        '[EXAMPLES]:\\n'\n",
    "        '# OK:\\n'\n",
    "        '- What is the meaning of RGS?\\n'\n",
    "        '- When does RGS established?\\n'\n",
    "        '- Where does RGS established?\\n'\n",
    "        '- What services are RGS provided? \\n'\n",
    "        '- Is RGS hiring IT Engineers this year?\\n'\n",
    "        '# NG:\\n'\n",
    "        '- Please show me the financial report of RGS.\\n'\n",
    "        '- Please show me the design documents about ATgo developed by RGS.'\n",
    "    )\n",
    "\n",
    "    get_weather_prompt = (\n",
    "        \"[Intent Name]: get_weather\\n\"\n",
    "        \"[Definition] The given inputs are about asking weather.\\n\"\n",
    "        \"You can follow to EXAMPLES below. \\n\"\n",
    "        '[EXAMPLES]:\\n'\n",
    "        '# OK:\\n'\n",
    "        '- What is the weather of tomorrow?\\n'\n",
    "        '- What is the weather of 1st, Sept. 2024?\\n'\n",
    "        '- Will it rain tomorrow?\\n'\n",
    "        '- What is the temperature of tomorrow? \\n'\n",
    "        '- Will it rain tomorrow in Tokyo?\\n'\n",
    "        '# NG:\\n'\n",
    "        '- What is now?\\n'\n",
    "        '- What is your name?\\n'\n",
    "        '[Note]:\\n'\n",
    "        '- The output of arguments should containes following items.\\n'\n",
    "        '  * time: datetime\\n'\n",
    "        '  * address: str'        \n",
    "    )\n",
    "    \n",
    "    current_time_prompt = (\n",
    "        \"[Intent Name]: current_time\\n\"\n",
    "        \"[Definition] The given inputs are about asking current time.\\n\"\n",
    "        \"You can follow to EXAMPLES below. \\n\"\n",
    "        '[EXAMPLES]:\\n'\n",
    "        '# OK:\\n'\n",
    "        '- What is now?\\n'\n",
    "        '- Is it 1st, Sept. 2024, today?\\n'\n",
    "        '- What day of the week is it today?\\n'\n",
    "        '- Is it Tuesday today? \\n'\n",
    "        '# NG:\\n'\n",
    "        '- What is RGS?\\n'\n",
    "        '- What is your name?'\n",
    "    )\n",
    "\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", ask_question_about_rgs_prompt),\n",
    "        (\"ai\", \"OK. I understand the intent 'ask_question_about_rgs'.\"),\n",
    "        (\"human\", get_weather_prompt),\n",
    "        (\"ai\", \"OK. I understand the intent 'get_weather'.\"),\n",
    "        (\"human\", current_time_prompt),\n",
    "        (\"ai\", \"OK. I understand the intent 'current_time'.\"),\n",
    "        (\"human\", \"That all the intents defined.\"),\n",
    "        (\"ai\", \"OK. Please give me your input. I will do classification based on all defined intents.\"),        \n",
    "        (\"human\", \"{{ \\\"input\\\": {question} }}\"),\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "    return prompt_template | llm\n",
    "\n",
    "chain = build_intent_classifier()\n",
    "\n",
    "text = \"ä»Šã¯ä½•æ™‚ã§ã™ã‹ï¼Ÿ\"\n",
    "response = chain.invoke({\n",
    "    \"question\": text\n",
    "})\n",
    "show_answer(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd1bed-79dc-4edd-8487-67db4b41a342",
   "metadata": {},
   "source": [
    "## 3. è¯æ§½å¡«å……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f123a8df-0595-4094-b5d4-653e1af541a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 47\u001b[0m\n\u001b[1;32m      1\u001b[0m slot_extraction_prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are an AI assistant, reading the transcript of a conversation between an AI and a human.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mFrom the last line of the conversation, extract all proper named entity(here denoted as slots) that match about asking for weather information.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124mOutput Slots:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 47\u001b[0m slot_extraction_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m(\n\u001b[1;32m     48\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslots\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     49\u001b[0m     template\u001b[38;5;241m=\u001b[39mslot_extraction_prompt_template,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m chain \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(slot_extraction_prompt_template) \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "slot_extraction_prompt_template = \"\"\"\n",
    "You are an AI assistant, reading the transcript of a conversation between an AI and a human.\n",
    "From the last line of the conversation, extract all proper named entity(here denoted as slots) that match about asking for weather information.\n",
    "Named entities required for querying weather information include date time, address.\n",
    "\n",
    "The output should be returned in the following json format.\n",
    "{{\n",
    "    \"datetime\": \"Define the date and time identified from the conversation. It should be defined in ISO format: yyyy-MM-dd HH:mm:ss.\"\n",
    "    \"address\": \"Define city/country identified from the conversation.\"\n",
    "}}\n",
    "\n",
    "If there is no match for each slot, assume null.(e.g., user is simply saying hello or having a brief conversation).\n",
    "\n",
    "EXAMPLE\n",
    "Conversation history:\n",
    "Person #1: I want to know the weather today.\n",
    "AI: \"Hiï¼Œwhich city do you want to know?\"\n",
    "Current Slots: {{\"datetime\": null, \"address\": null}}\n",
    "Last line:\n",
    "Person #1: Tokyo\n",
    "Output Slots: {{\"datetime\": null, \"address\": \"Tokyo\"}}\n",
    "END OF EXAMPLE\n",
    "\n",
    "EXAMPLE\n",
    "Current datetime: 2023/04/10 11:20\n",
    "Conversation history:\n",
    "Person #1: I want to know the weather of Tokyo.\n",
    "AI: OK, what time do you want to know?\n",
    "Current Slots: {{\"datetime\": null, \"address\": \"Tokyo\" }}\n",
    "Last line:\n",
    "Person #1: Tomorrow at 8 a.m.\n",
    "Output Slots: {{\"datetime\": \"2023/08/26 08:00\", \"address\": \"Tokyo\", }}\n",
    "END OF EXAMPLE\n",
    "\n",
    "Output Slots must be in json format!\n",
    "\n",
    "Begin!\n",
    "Current datetime: {current_datetime}\n",
    "Conversation history (for reference only):\n",
    "{history}\n",
    "Current Slots:\n",
    "{slots}\n",
    "Last line of conversation (for extraction):\n",
    "Human: {input}\n",
    "\n",
    "Output Slots:\"\"\"\n",
    "slot_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"slots\", \"current_datetime\"],\n",
    "    template=slot_extraction_prompt_template,\n",
    ")\n",
    "\n",
    "chain = ChatPromptTemplate.from_template(slot_extraction_prompt_template) | llm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"current_datetime\": datetime.now().isoformat(),\n",
    "    \"history\": \"\",\n",
    "    \"slots\": json.dumps({\"datetime\": None, \"address\": None }),\n",
    "    \"input\": \"ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ\"\n",
    "})\n",
    "\n",
    "show_answer(res)\n",
    "\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"current_datetime\": datetime.now().isoformat(),\n",
    "    \"history\": \"\",\n",
    "    \"slots\": json.dumps({\"datetime\": None, \"address\": None }),\n",
    "    \"input\": \"æ˜æ—¥ã€æ±äº¬éƒ½ã®å¤©æ°—ã¯ï¼Ÿ\"\n",
    "})\n",
    "\n",
    "show_answer(res)\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"current_datetime\": datetime.now().isoformat(),\n",
    "    \"history\": \"\"\"\n",
    "    Human: æ˜æ—¥ã®å¤©æ°—ã¯ï¼Ÿ\n",
    "    AI: ã©ã“ã®å¤©æ°—ã‚’çŸ¥ã‚ŠãŸã„ã‹ï¼Ÿ\n",
    "    \"\"\",\n",
    "    \"slots\": json.dumps({\"datetime\": None, \"address\": None }),\n",
    "    \"input\": \"æ±äº¬éƒ½\"\n",
    "})\n",
    "\n",
    "show_answer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8034b-44f0-41be-ba42-ab1af789d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prompt_template = \"\"\"\n",
    "You are an AI assistant for answering weather information.\n",
    "\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "The Current Slots shows all the information you need to query weather information.\n",
    "If datetime is null with respect to the Current Slots value, ask a question about the date time of weather when human want to know.\n",
    "If address is null with respect to the Current Slots value, ask a question about the city/courtry where human want to know.\n",
    "\n",
    "If the Information check is True, it means that all the information required for getting weather info has been collected,\n",
    "the AI should output \"OK\" and return the booking information in the following way:\n",
    "datetime:\n",
    "addressï¼š\n",
    "\n",
    "Do not repeat the human's response!\n",
    "Do not output the Current Slots!\n",
    "\n",
    "Begin!\n",
    "Information check:\n",
    "{check}\n",
    "Current conversation:\n",
    "{history}\n",
    "Current Slots:\n",
    "{slots}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "chain = ChatPromptTemplate.from_template(check_prompt_template) | llm\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"check\": False,\n",
    "    \"history\": \"\"\"\n",
    "    Human: æ˜æ—¥ã®å¤©æ°—ã¯ï¼Ÿ\n",
    "    AI: ã©ã“ã®å¤©æ°—ã‚’çŸ¥ã‚ŠãŸã„ã‹ï¼Ÿ\n",
    "    \"\"\",\n",
    "    \"slots\": json.dumps({\"datetime\": \"2024-08-06T00:00:00\", \"address\": None }),\n",
    "    \"input\": \"æ±äº¬éƒ½\"\n",
    "})\n",
    "\n",
    "show_answer(res)\n",
    "\n",
    "\n",
    "chain = ChatPromptTemplate.from_template(check_prompt_template) | llm\n",
    "\n",
    "res = chain.invoke({\n",
    "    \"check\": True,\n",
    "    \"history\": \"\"\"\n",
    "    Human: æ˜æ—¥ã®å¤©æ°—ã¯ï¼Ÿ\n",
    "    AI: ã©ã“ã®å¤©æ°—ã‚’çŸ¥ã‚ŠãŸã„ã‹ï¼Ÿ\n",
    "    \"\"\",\n",
    "    \"slots\": json.dumps({\"datetime\": \"2024-08-06T00:00:00\", \"address\": \"æ±äº¬éƒ½\" }),\n",
    "    \"input\": \"æ±äº¬éƒ½\"\n",
    "})\n",
    "\n",
    "show_answer(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
